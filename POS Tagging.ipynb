{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # For creating dataframes of extracted information\n",
    "# NLP Specific Libraries\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(sent):\n",
    "  head_entity = \"\"\n",
    "  candidate_entity = \"\"\n",
    "\n",
    "  prv_tok_dep = \"\"    \n",
    "  prv_tok_text = \"\"  \n",
    "\n",
    "  prefix = \"\"\n",
    "  words_ = []\n",
    "  label_ = []\n",
    "  tags_ = []\n",
    "\n",
    "  doc = nlp(sent) \n",
    "  \n",
    "  for tok in doc:\n",
    "      words_.append(tok.text)\n",
    "      label_.append(tok.pos_)\n",
    "      \n",
    "\n",
    "\n",
    "  return (pd.DataFrame({'Token': words_, 'POS': label_}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tokenization of Corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "Raw_txt = \"\"\n",
    "files = [file for file in glob.glob(r'C:\\\\Users\\\\Hp\\\\Desktop\\\\Rule-Based-Dataset\\\\RAW\\\\*.txt')]\n",
    "for file_name in files:\n",
    "    with open(file_name,\"r+\") as file:\n",
    "        Raw_txt += file.read() + \"\\n\" # I added a new line in case you want to separate the different text content of each file\n",
    "#print(Raw_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PETITIONER</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STATE</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OF</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>Appeals</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>dis-</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>missed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7904 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token    POS\n",
       "0     PETITIONER  PROPN\n",
       "1              :  PUNCT\n",
       "2            THE    DET\n",
       "3          STATE   NOUN\n",
       "4             OF    ADP\n",
       "...          ...    ...\n",
       "7899     Appeals  PROPN\n",
       "7900        dis-   PRON\n",
       "7901      missed   VERB\n",
       "7902           .  PUNCT\n",
       "7903          \\n  SPACE\n",
       "\n",
       "[7904 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset(Raw_txt) #calling function for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_DB = get_dataset(Raw_txt) #saving to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dataset in CSV Format\n",
    "dataset_DB.to_csv(r'C:\\\\Users\\\\Hp\\\\Desktop\\\\Rule-Based-Dataset\\\\Dataset_Data\\\\Legal_DataSet.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a4109cd9b05f6c871021d5e7a6a2f8acb4b485c83beb01dc86a87ec39b9e06a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
